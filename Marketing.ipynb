{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT REQUIRED MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PartialDependenceDisplay\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\", sep = \";\")\n",
    "df_test = pd.read_csv(\"test.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_legend = pd.concat([df_train, df_test], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: DROP DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(inplace = True)\n",
    "df_test.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: FILL MISSING DATA OR NaN VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df_train[col]):\n",
    "        df_train[col] = df_train[col].fillna(df_train[col].median())\n",
    "    else:\n",
    "        df_train[col] = df_train[col].fillna(\"unknown\")\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df_test[col]):\n",
    "        df_test[col] = df_test[col].fillna(df_test[col].median())\n",
    "    else:\n",
    "        df_test[col] = df_test[col].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: DISREGARD THE SPECIAL CHARACTERS IN THE TEXT FIELDS, IF ANY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z09\\s]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Apply one-hot encoding to categorical columns in the training and test sets, \n",
    "## dropping the first category to avoid the dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded = pd.get_dummies(df_train, drop_first = True)\n",
    "df_test_encoded = pd.get_dummies(df_test, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: CHECK FOR NULL VALUES IN THE ENCODED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_encoded.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: COMBINE THE ENCODED TRAIN AND TEST DATA INTO ONE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df_train_encoded, df_test_encoded], ignore_index = True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: Remove columns with less useful or less relevant categories from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['job_unknown'], axis=1)\n",
    "df2 = df2.drop(['education_unknown'], axis=1)\n",
    "df2 = df2.drop(['contact_unknown'], axis=1)\n",
    "df2 = df2.drop(['poutcome_unknown'], axis=1)\n",
    "df2 = df2.drop(['poutcome_other'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST THE DATA WITH LOGISTIC REGRESSION MODEL AND PRINT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"poutcome_success\"\n",
    "\n",
    "x = df2.drop(target, axis = 1)\n",
    "y = df2[target]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "model = LogisticRegression(max_iter = 9000, solver = \"saga\")\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Accuracy : {accuracy : .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict_proba(x_test)[:, 1]\n",
    "x_test_prob = x_test.copy()\n",
    "x_test_prob[\"pred_prob\"] = y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_prob.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_legend.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT AND TRANSFORM THE MODEL DATA AND FIND THE FEATURE IMPORTANCE BASED ON LOGISTIC REGRESSION COEFFICIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "model_std = LogisticRegression(max_iter = 9000, solver = \"saga\")\n",
    "model_std.fit(x_train_scaled, y_train)\n",
    "\n",
    "coefs = model_std.coef_[0]\n",
    "feature_names = x_test.columns\n",
    "\n",
    "coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
    "coef_df['AbsCoefficient'] = coef_df['Coefficient'].abs()\n",
    "coef_df.sort_values(by='AbsCoefficient', ascending = False, inplace = True)\n",
    "\n",
    "print(\"Feature importance based on logistic regression coefficients:\")\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.bar(coef_df['Feature'], coef_df['AbsCoefficient'], color = 'skyblue')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Absolute Coefficient')\n",
    "plt.title('Feature Importance Based on Absolute Coefficients')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST THE DATA WITH XGB CLASSIFIER MODEL AND PRINT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,       # Number of trees\n",
    "    learning_rate=0.1,      # Learning rate\n",
    "    max_depth=3,            # Maximum tree depth\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'     # Evaluation metric\n",
    ")\n",
    "\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(x_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"XGBoost Model Accuracy: {:.2f}\".format(accuracy_xgb))\n",
    "\n",
    "y_pred_prob_xgb = xgb_model.predict_proba(x_test)[:, 1]\n",
    "x_test_prob_xgb = x_test.copy()\n",
    "x_test_prob_xgb[\"pred_prob\"] = y_pred_prob_xgb\n",
    "\n",
    "xgb.plot_importance(xgb_model, max_num_features=10, importance_type='gain')\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_prob_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARE THE PERFORMANCE OF BOTH MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(y_pred_prob, bins=20, alpha=0.5, label='Logistic Regression')\n",
    "plt.hist(y_pred_prob_xgb, bins=20, alpha=0.5, label='XGBoost')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Predicted Probabilities: Logistic Regression vs XGBoost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_prob_xgb.sort_values(by='pred_prob', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_prob_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_prob_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_prob_xgb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose df is your full DataFrame with a 'pred_prob' column.\n",
    "# First, filter for high-probability customers.\n",
    "high_prob = x_test_prob_xgb[x_test_prob_xgb['pred_prob'] > 0.72].copy()\n",
    "\n",
    "# List of target features.\n",
    "features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Dictionary to store the common range (IQR) for each feature.\n",
    "common_ranges = {}\n",
    "\n",
    "# Remove outliers from each feature using the 1.5 * IQR rule.\n",
    "for col in features:\n",
    "    Q1 = high_prob[col].quantile(0.25)\n",
    "    Q3 = high_prob[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Save the common range (the IQR)\n",
    "    common_ranges[col] = (Q1, Q3)\n",
    "    \n",
    "    # Remove outliers for this feature.\n",
    "    high_prob = high_prob[(high_prob[col] >= lower_bound) & (high_prob[col] <= upper_bound)]\n",
    "\n",
    "# Display the most common range for each feature.\n",
    "print(\"Most common ranges (IQR) for each feature:\")\n",
    "for col, rng in common_ranges.items():\n",
    "    print(f\"{col}: {rng}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of columns to consider\n",
    "columns_list = [\n",
    "    'job_blue-collar', 'job_entrepreneur', 'job_housemaid', \n",
    "    'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
    "    'job_student', 'job_technician', 'job_unemployed', 'marital_married',\n",
    "    'marital_single', 'education_secondary', 'education_tertiary',\n",
    "    'default_yes', 'housing_yes', 'loan_yes', 'contact_telephone',\n",
    "    'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul',\n",
    "    'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct',\n",
    "    'month_sep', 'y_yes'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame for rows where 'pred_prob' > 0.72\n",
    "filtered_df = x_test_prob_xgb[x_test_prob_xgb['pred_prob'] > 0.72]\n",
    "\n",
    "# Create a dictionary to store counts for each column\n",
    "counts = {}\n",
    "\n",
    "# For each column in the list, count the rows where the column is True (or 1)\n",
    "for col in columns_list:\n",
    "    if col in filtered_df.columns:\n",
    "        # If the column is numeric (0/1) or boolean, this will work.\n",
    "        # If the column is a string, you might need to map it to a boolean.\n",
    "        count_true = filtered_df[col].astype(bool).sum()\n",
    "        counts[col] = count_true\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts for each column where pred_prob > 0.72 and the column is True:\")\n",
    "for col, count in counts.items():\n",
    "    print(f\"{col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the counts dictionary based on your extracted data\n",
    "counts = {\n",
    "    'job_blue-collar': 4,\n",
    "    'job_entrepreneur': 2,\n",
    "    'job_housemaid': 1,\n",
    "    'job_management': 5,\n",
    "    'job_retired': 13,\n",
    "    'job_self-employed': 0,\n",
    "    'job_services': 2,\n",
    "    'job_student': 2,\n",
    "    'job_technician': 8,\n",
    "    'job_unemployed': 3,\n",
    "    'marital_married': 29,\n",
    "    'marital_single': 11,\n",
    "    'education_secondary': 17,\n",
    "    'education_tertiary': 18,\n",
    "    'default_yes': 0,\n",
    "    'housing_yes': 0,\n",
    "    'loan_yes': 0,\n",
    "    'contact_telephone': 7,\n",
    "    'month_aug': 7,\n",
    "    'month_dec': 0,\n",
    "    'month_feb': 4,\n",
    "    'month_jan': 1,\n",
    "    'month_jul': 3,\n",
    "    'month_jun': 3,\n",
    "    'month_mar': 2,\n",
    "    'month_may': 5,\n",
    "    'month_nov': 0,\n",
    "    'month_oct': 7,\n",
    "    'month_sep': 9\n",
    "}\n",
    "\n",
    "def get_max_category(counts, prefix):\n",
    "    # Filter the dictionary for keys starting with the prefix\n",
    "    filtered = {k: v for k, v in counts.items() if k.startswith(prefix)}\n",
    "    if filtered:\n",
    "        # Find the key with the maximum count\n",
    "        max_key = max(filtered, key=filtered.get)\n",
    "        return max_key, filtered[max_key]\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Extract the maximum for each category\n",
    "max_job, job_count = get_max_category(counts, 'job_')\n",
    "max_marital, marital_count = get_max_category(counts, 'marital_')\n",
    "max_education, education_count = get_max_category(counts, 'education_')\n",
    "max_month, month_count = get_max_category(counts, 'month_')\n",
    "\n",
    "print(\"Most common job:\", max_job, \"with count:\", job_count)\n",
    "print(\"Most common marital status:\", max_marital, \"with count:\", marital_count)\n",
    "print(\"Most common education:\", max_education, \"with count:\", education_count)\n",
    "print(\"Most common month:\", max_month, \"with count:\", month_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if the data we get is in this:\n",
    "\n",
    "age: (np.float64(34.75), np.float64(64.25))\n",
    "balance: (np.float64(547.25), np.float64(3530.25))\n",
    "day: (np.float64(9.0), np.float64(17.5))\n",
    "duration: (np.float64(244.75), np.float64(423.0))\n",
    "campaign: (np.float64(1.0), np.float64(2.0))\n",
    "pdays: (np.float64(181.0), np.float64(183.0))\n",
    "previous: (np.float64(1.0), np.float64(4.0))\n",
    "\n",
    "range and has got:\n",
    "\n",
    "job as retired, marriage as married, education as tertiary and last contacted month of year as september\n",
    "\n",
    "Then that is Our Guy and We will be sending personalized data using genai prompt and the Guy's data as per datasheet.\n",
    "\n",
    "***(It is yet to be done. We need to learn more about using such models using apis)***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
